# Model size: 494M params
# 0.5 to 72 billion parameters and it is based on the Transformer architecture with SwiGLU activation, attention QKV bias, group query attention, etc
MODEL_ID=Qwen/Qwen2-0.5B

OMDB_API_KEY=4aa95a07
SENTIMENT_MODEL=siebert/sentiment-roberta-large-english
